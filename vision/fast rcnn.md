# Fast R-CNN

R-CNN有如下缺点：

+ 训练过程多阶段
+ 训练在时间和空间上都很昂贵
+ 目标检测缓慢（VGG16 47秒）

R-CNN速度很慢，因为它对每个建议区域都执行向前传播，而不是共享计算（sharing computation)。SPPnets（Spatial pyramid pooling networks）被提出通过共享计算加速R-CNN。SPPnet的方法将整个图像输入计算卷积特征映射，然后使用提取自共享特征映射的特征向量来对每个目标区域定位。通过将建议区域中的特征映射的部分最大池化为固定大小的输出，为建议区域提取特征。池化出多个输出大小，然后像空间金字塔一样连接起来。SPPnet在测试阶段加速R-CNN10倍到100倍，训练阶段加速了3倍。

SPPnet也有明显的缺点，训练有多个过程（提取特征，微调网络，训练SVM，拟合边界框回归）。

[对SPPnet网络的理解](<https://www.cnblogs.com/gongxijun/p/7172134.html>)

Fast R-CNN的优点：

- 比R-CNN，SPPnet更高的检测质量（mAP）
- 训练是单阶段的，使用多任务的损失
- 训练可以更新所有网络层
- 特征缓存不需要硬盘存储）

### Fast R-CNN 架构和训练

Fast R-CNN网络将整张图片和目标区域集合作为输入。网络首先将用多个卷积和最大池化层处理整张图片产生一个卷积特征映射。然后对于每个目标区域，使用RoI（region of interest）池化层从特征映射中提取固定长度的特征向量。将每个特征向量喂给多个全连接层最终分为两个输出层：一个K个目标类加背景类的softmax概率评估（分类器），另一个是关于每个目标类的四个实值（边框拟合）。

![](F:\mycode\knowledgeArrangement\vision\frcnn.jpg)

#### RoI池化层

最大池化层使用最大池化将位于RoI中的特征转化为拥有固定空间范围的小的而调整映射（$H \times W$），H和W是层的超参数独立于任何特别的RoI。在本文中，RoI是一个矩形窗口到一个conv特征映射。每个RoI都被定义为一个四元组($r,c,h,w$)，指定左上角($r, c$)和它的高度和宽度($h, w$)。

![avarta](F:\mycode\knowledgeArrangement\vision\fast rcnn.png)

RoI最大池化：将$h \times w$的RoI窗口划分成$h/H \times w/W$的子空间，这样会有$H \times W$个子空间，然后最这些子空间做最大池化。池化操作独立应用于每个特征映射通道，就像标准的最大池化那样。RoI层只是the spatial pyramid pooling层的特殊情况。

#### 从与训练网络中初始化

当一个预先训练好的网络初始化一个fast R-CNN网络时，会经历三个转换：首先，最后一层最大池化层被替换为RoI池化层，将H和W设置为于网络的第一个全连接层兼容。然后，将网络最后一层全连接层和softmax替换为两个分支（上文已经描述过了）。最后，将网络修改为接受两个数据输入，图像列表和这些图像的RoI列表。

#### 检测微调

（原论文中解释为什么SPPnet网络反向传播效率低的原因，面试注意！）

本文提出了一种利用训练过程中特征共享的高效训练方法：在Fast RCNN训练中，随机梯度下降的小批量是被分层采样的，首先采样N张图片，然后从每张图片中采样R/N张RoIs。关键在于，相同图像的RoI在前向和反向传播中共享计算和内存。使用小的N就减小了小批量的计算量。Fast R-CNN使用了一个精简的训练过程：联合优化一个softmax分类器和边框回归器。而不是在三个分开的阶段训练一个softmax分类器，SVM和回归器。

**多任务损失**：

Fast R-CNN有两个分开的输出层。第一个输出了离散的概率分布（每个RoI），$p=(p_{0}, \cdots, p_{K})$，K+1个分类。

第二个输出了边界框回归偏移量，$t^{k}=(t^{k}_{x}, t^{k}_{y}, t^{k}_{w}, t^{k}_{h})$（和rcnn用法一样）。每个训练用的RoI都被标记为真实类u和真实边框回归目标v。我们使用多任务损L来联合训练分类和边框回归：
$$
L(p,u,t^{u},v)=L_{cls}(p, u)+\lambda [u \geq 1]L_{loc}(t^{u},v)
$$
$L_{cls}(p,u)=-log p_{u}$是真实类u的log损失函数。对于$L_{loc}$，定义$v=(u_{x}, u_{y}, u_{w}, u_{h})$，和预测$t^{u}=(t^{u}_{x},t^{u}_{y},t^{u}_{w},t^{u}_{h})$，$[u \geq 1]$指当$u \geq 1$时值为1否则为0。按照惯例，将背景类标记为$u=0$。对于边框回归，使**用损失函数**：
$$
L_{loc}(t^{u},v)=\sum_{i \in \{ x,y,w,h \}} smooth_{L_{1}}(t^{u}_{i}-v_{i}) \\
smooth_{L_{1}}(x)=\left\{\begin{matrix}
0.5x^{2} & if \left | x \right | < 1 \\ 
\left | x \right | -0.5 & otherwise 
\end{matrix}\right.
$$
*对于边框预测回归问题，通常也可以选择平方损失函数（L2损失），但L2范数的缺点是当存在离群点时，这些点会占loss的主要成分。所以Fast RCNN采用稍微缓和一点的绝对损失函数（smooth L1损失），它随着误差线性增长，而不是平方增长。注意：smooth L1和L1-loss函数的区别在于，L1-loss在0处不可导，可能影响收敛，而smooth L1的解决方法是在0点附近使用平方函数使它更加的平滑。*

​	这种鲁棒的L1损失相较于R-CNN和SPPnet的L2损失对于离群点更加不敏感。当回归目标是无界的，使用L2损失的训练可能要仔细调整学习速率以防止梯度爆炸。

​	超参数$\lambda$控制了两个任务损失的平衡度。对真实回归目标做标准化处理（均值为0方差为1）。

**小批量采样**：

​	25%的RoIs来自于与真实边框IoU大于等于0.5的建议区域，这些样本被标注为对应的前景目标类。剩下的RoIs采样于最大IoU在[0.1, 0.5]之间的建议区域，这些样本被标注为背景。低于阈值的0.1的样本作为hard example mining。训练过程中有0.5的概率对图像做水平翻转来实现数据增强。

**RoI pooling layers的反向传播**：

令$X_{i} \in \mathbb{R}$是RoI pooling layer的第i个激活输入令$y_{rj}$是第r个RoI的j个输出。RoI pooling layer计算$y_{rj}=x_{i*(r,j)}$，$i*(r,j)=argmax_{i' \in R(r,j)}x_{i'}$。R(i,j)是输出单元$y_{rj}$输入被分割的子窗口集合的对应序号。反向传播中计算损失函数对输入$x_{i}$的偏导数如下：
$$
\frac{\partial L}{\partial x_{i}}=\sum_{r} \sum_{j} [i=i^{*}(r,j)] \frac{\partial L}{\partial y_{rj}}
$$
**规模不变性**：

使用两种方法获得规模不变性目标检测：

+ 暴力学习
+ 使用图像金字塔

使用暴力方法时，在训练和测试期间，每个图像都按照预先定义的像素大小进行处理。网络必须从训练数据中学习尺度不变的目标检测。在多变的规模方法中，通过图像金字塔提供规模近似的规模不变性。如SPPnet

### Fast R-CNN 检测

网络将一张图像（或者图像金字塔，编码为图像列表）和R个建议目标（object proposals）的列表作为输入进行评分。对于每个测试RoI r，前向传播输出类的后验概率分布p和相对于r的预测的边框偏移（每个K类都有子集的边框预测）。我们给r为每个目标类k分配一个检测置信度，使用评估改概率$Pr(class=k|r) \doteq p_{k}$。然后对每个类使用非极大值抑制，和R-CNN一样。

#### Truncated SVD for faster detection

​	对于全图像分类，于卷积层相比，计算全连通层所花费的时间比较小。相反，对于检测而言，要处理的RoI数量很大，全连接层的计算花费的时间占正向传播的一般。使用截断SVD压缩大的全连接层来加速。

​	在该技术中，参数矩阵W（$u \times v$）使用[SVD](F:\mycode\knowledgeArrangement\machineLearning\svd.md)近似分解为：
$$
W \approx U \Sigma_{t}V^{T}
$$

​	U是$u \times t$的由W的前t个左奇异向量组成的矩阵。$\Sigma _{t}$是$t \times t$的对角矩阵，包含了矩阵W最大的t个奇异值。V是$v \times t$的由W的前t个右奇异向量组成的矩阵。**截断SVD将参数从$uv$减少到了$t(u+v)$个，如果t远远小于u和v，那么将显著提高效率。为了压缩网络，将于W对应的单个全连接层替换为两个全连接层，它们之间不存在非线性层。第一层权重矩阵为$\Sigma_{t}V^{T}$（没有偏置），第二层权重矩阵为$U$（于最初W的偏置相关）。当RoI的数量较大时，这种简单的压缩方法可以很好的加速。**

### 设计评估

多任务训练很方便，因为它避免了管理一系列连续训练的任务。它也有可能改进结果，因为任务通过共享表示互相影响（卷积网络）。

#### 多任务训练有帮助吗？

*多任务训练能搜提高Fast R-CNN的目标检测精度？*

是的，在论文的实验中，观察到多任务训练相对于单独的分类训练提高了纯分类精度，显示了多任务学习的一致积极效果。

#### 规模不变性：蛮力还是技巧

深度卷积网络善于直接学习尺度不变性。多比例方法只在mAP上提供了小的增加，但在计算时间上花费很大。因为单尺度处理提供了速度和精度之间的最佳权衡，特别是对于非常深的模型。

一个好的目标检测器应该在提供更多的训练数据时得到改进。

### 结论

特别注意：稀疏目标建议似乎可以提高检测器的质量。

