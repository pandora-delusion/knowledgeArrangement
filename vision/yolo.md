# Yolo

目标检测流行的两大类：

1. 基于Region Proposal的R-CNN系列算法（R-CNN，Fast R-CNN，Faster R-CNN），它们都是two-stage的，需要先使用启发式方法（selective search等）或者卷积网络（RPN）产生的Region Proposal，然后再Region Proposal上做分类和回归。
2. 类似Yolo，SSD这类one-stage算法，其仅仅使用一个CNN网络直接预测不同目标的类别和位置。

第一种方法准确度高，速度慢，第二种方法速度下，准确度低一些。

Yolo是一种能够同时预测多个边框坐标和分类概率的单一卷积神经网络。这意味着可以对整个图像和图像中的所有对象进行全局推理。

**yolo的优点**：

1. 采用单一管道策略，端到端的训练和测试，算法简洁速度快。
2. 在训练和测试期间能看到整个图像，因此它隐式地编码有关分类和外观的上下文信息。
3. 泛化能力强，在做迁移时，模型鲁棒性高

**yolo的缺点**：

1. 很难精确定位某些对象，尤其是小对象
2. Yolo对边界框预测施加了很强的空间限制，各个单元格仅仅预测两个边界框，而指属于一个类别。这种空间约束限制了我们的模型可以预测的邻近对象的数量。
3. 因为模型是是从数据中预测边界框，它很难推广到新的或者不寻常的长宽比或者配置中的对象。

### 设计理念

Yolo算法采用一个单独的CNN模型实现end-to-end的目标检测，首先将输入图片resize到448$\times$448，然后送入CNN网络，最后处理网络预测结果得到检测的目标。Yolo的训练和测试过程都是端到端的。

yolo通过卷积网络对输入图像进行特征，如论文中，将448$\times$448$\times$3的输入通过卷积网络的特征提取，得到$7\times7\times1024$的输出，然后将输出的张量flat成向量喂给全连接层。全连接层最后的输出将有$7\times 7 \times 30$的维度，如下图所示：

![](F:\mycode\knowledgeArrangement\vision\yolo.jpg)

​	具体来说，yolo的CNN网络将输入图片的**特征图**分割成$S\times S$的网格，然后每个网格去检测那些中心点落在该格子内的目标。每个单元格会预测B个边界框以及边界框的置信度（confidence score）。所谓的置信度其实包含两个方面，一是这个边界框含有目标的可能性大小，二是这个边框的准确度。前者记为$Pr(object)$，当边框是背景时，$Pr(object)=0$。而当该边界框包含目标时，$Pr(object)=1$。边界框的准确度可以用预测框和实际框（ground truth）的IoU来表征，记为$IoU_{pred}^{truth}$。因此置信度可以表示为$Pr(object) \times IoU_{pred}^{truth}$。边界框的大小与位置可以用4个值来表征(x, y, w, h)，其中(x, y)是边界框的中心坐标，而w和h是边界框的宽与高。注意，中心坐标的预测值（x，y）是相对于**每个特征单元格对应的原图片区域左上角坐标点的偏移值**，并且单位是相对于单元格大小的。而边框的w和h预测值是相对于整个图片的高与宽的比例，理论上x，y在[0,1]范围内，但w和h可能有大于1的情况（但论文里说都是在[0, 1]范围内）。这样，每个边界框的预测值实际上包含5个元素：$(x,y, w, h, c)$其中前四个表征边界框的大小与位置，而最后一个是置信度。

​	还有分类问题，对于每个但与个还要给出C个类别概率值，其表征的是由该单元格负责预测的边界框其目标属于各个类别的概率。但是这些概率值其实是在各个边界框置信度下的条件概率，即$Pr(class_{i}|object)$。但是**不管一个单元格预测多少个边界框，其只预测一组类别概率值，这是Yolo算法的一个缺点**。同时，我们可以计算处各个边框类别置信度（class-specific confidence scores）：
$$
Pr(class_{i}|object)\cdot Pr(object) \cdot IoU_{pred}^{truth}=Pr(class_{i}) \cdot IoU_{pred}^{truth}
$$
​	所以，每个单元格需要预测$(B \cdot 5+C)$个值。如果将输入图片的特征图划分为$S \times S$的网格，那么最终预测值为$S \times S \times (B \cdot 5 + C)$大小的张量。所以正如上面所述，令$S=7,B=2$，那么全连接层的输出为$7 \times 7 \times 30 $大小的张量。

![](F:\mycode\knowledgeArrangement\vision\yolo_jg.jpg)

### 网络设计

​	Yolo采用卷积网络提取特征，然后使用全连接层来得到预测值。网络结构参考GooLeNet模型，包含24个卷积层和2个全连接层，如上图所示。对于卷积层，主要使用1x1卷积来做channel reduction，然后紧跟3x3卷积。对于卷积层和全连接层，采用Leaky ReLU激活函数：$max(x, 0.1x)$。但是最后一层却采用线性激活函数。

​	对于每一个单元格，前20个元素是类别概率值，然后2个元素是边界框置信度，两者相乘可以得到类别置信度，最后8个元素是边界框的$(x, y, w, h)$。

### 网络训练

​	在训练之前，现在ImageNet上进行了预训练，其预训练的分类模型采用20个卷积层（上图），然后添加一个average-pool层和全连接层。预训练之后，在预训练得到的20层卷积层之上加上随机初始化的4个卷积层和2个全连接层。由于检测任务一般需要更高清的图片，所以将网络的输入从224x224增加到了448x448。

​	最后一层预测类别概率和边界框坐标。在损失函数的计算上，Yolo算法采用的是均方损失函数，虽然它很容易优化，但是并不完全符合最大化平均精度的目标。它对定位误差和分类误差的权重相等，这可能不是理想。而且，在每张图像中，许多网络单元格不包含任何对象。这将这些单元格的“置信度”分数推向0，这通常会压倒包含对象的单元格的梯度。这可能会导致模型的不稳定，导致训练在早期发散。所以对不同的部分采用了不同的权重值。对于定位误差，即边界框坐标预测误差，采用较大的权重$\lambda_{coord}=5$。不包含目标的边界框采用较小的权重值$\lambda_{noobj}=0.5$。其他权重值设为1。然后采用均方误差，其同等对待大小不同的边界框，但是实际上较小的边界框的坐标误差应该要比较大的边界框更加敏感，所以为了保证这一点，将网络的边界框的宽和高预测改为对其平方根的预测，即预测值变为$(x, y, \sqrt{w}, \sqrt{h})$。

​	另外一点时，由于每个单元格预测多个边界框。但是其对应类别只有一个。那么在训练时，如果该单元格内确实存在目标，那么只选择与ground truth的IOU最大的那个边界框来负责预测该目标，而其它边界框认为不存在目标。这样设置的一个结果将会使一个单元格对应的边界框更加专业化，其可以分别适用不同大小，不同高宽比的目标，从而提升模型性能。如果一个单元格内存在多个目标怎么办，其实这时候Yolo算法就只能选择其中一个来训练（yolo算法的缺点之一）。要注意的一点时，对于不存在对应目标的边界框，其误差项就是只有置信度，坐标项误差是没法计算的。而只有当一个单元格内确实存在目标时，才计算分类误差项，否则该项也是无法计算的。

损失函数如下：
$$
\begin{align*}
&\lambda_{coord} \sum_{t=0}^{S^{2}} \sum_{j=0}^{B}1_{ij}^{obj}[(x_{i}-\widehat{x}_{i})^{2}+(y_{i}-\widehat{y}_{i})^{2}]\\
&+\lambda_{coord}\sum_{i=0}^{S^{2}}\sum_{j=0}^{B}1_{ij}^{obj}[(\sqrt{w_{i}}-\sqrt{\widehat{w}_{i}})^{2}+(\sqrt{h_{i}}-\sqrt{\widehat{h}_{i}})^{2}]\\
&+\sum_{i=0}^{S^{2}}\sum_{j=0}^{B}1_{ij}^{obj}(C_{i}-\widehat{C}_{i})^{2}\\
&+\lambda_{noobj}\sum_{i=0}^{S^{2}}\sum_{j=0}^{B}1_{ij}^{noobj}(C_{i}-\widehat{C}_{i})^{2}\\
&+\sum_{i=0}^{S^{2}}1_{i}^{obj}\sum_{c \in classes}(P_{i}(c)-\widehat{P}_{i}(c))^{2}
\end{align*}
$$
​	$1_{ij}^{obj}$指的是第i个单元格存在目标，且该单元格中的第j个边界框复杂测试该目标。置信度的目标值$C_{i}$，如果是不存在目标，此时由于$Pr(object)=0$，那么$C_{i}=0$。如果存在目标，$Pr(object)=1$，此时需要确定$IoU_{pred}^{truth}$。

