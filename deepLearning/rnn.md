### 序列建模：循环和递归网络
参数共享的该概念体现在每个时间步中使用相同的卷积核，循环神经网络以不同的方式共享参数。输出的每一项是前一项的函数。输出的每一项对先前的输出应用相同的更新规则而产生。
$$h^{(t)}=f(h^{(t-1)},x^{(t)};\theta)$$

当循环神经网络根据过去预测未来时，网络通常要学会使用$h^{(t)}$作为过去序列（直到t）与任务相关方面的有损摘要。根据不同的训练准则，摘要可能选择性地精确保留过去序列的某些方面。最苛刻的情况是我们要求$h^{(t)}$足够丰富，并能大致恢复输入序列，如自编码器框架。 

无论序列的长度，学成的模型始终具有相同的输入大小，因为它指的是从一种状态到另一种状态的转移，而不是在可变长度的历史状态上操作。
学习单一的共享模型允许泛化到没有见过的序列长度（没有出现在训练集中），并且估计模型所需的训练样本远远少于不带参数共享的模型。

循环神经网络中的一些重要的设计模式包括以下几种：
+ 每个时间步都有输出，并且隐藏单元之间有循环连接的循环网络。
+ 每个时间步都产生一个输出，只有当前时刻的输出到下个时刻的隐藏单元之间有循环连接的神经网络
+ 隐藏单元之间存在循环连接，但读取整个序列后产生单个输出的循环网络

第二种RNN没有第一种RNN那么强大（只能表示更小的函数集合）。第一种RNN可以将其想要的关于过去的任何信息放入隐藏表示h中并将h传播到未来；第二种RNN被训练为将特定输出值作为允许传播到未来的唯一信息，此处没有从h前向传播的直接连接，之前的h仅通过产生的预测间接地连接到当前。第三种关于时间展开的循环神经网络，在序列结束时具有单个输出，这样的网络用于概括序列并产生用于进一步处理的固定大小的表示。在结束处可能存在目标，或者通过更快下游模块的反向传播来获得输出上的梯度。

第一种：
$$\alpha^{(t)}=b+\omega h^{(t-1)}+Ux^{(t)}$$$$h^{(t)}=tanh(\alpha^{(t)})$$$$o^{(t)}=c+Vh^{(t)}$$$$\widehat{y}^{(t)}=softmax(o^{(t)})$$
将相同长度的输入序列映射到相同长度的输出序列。与x序列配对的y的总损失就是所有时间步的损失之和。该反向传播无法通过并行化来降低，运行时间时$\Theta \left ( \gamma  \right )$，前向传播中的各个状态必须保存，直到它们在方向传播中被再次使用，因此内存代价也是$\Theta \left ( \gamma  \right )$。因此用于展开图且代价为$\Theta \left ( \gamma  \right )$的反向传播算法被称为通过时间反向传播（back-propagation through time，BPTT）。训练代价很大。

第二种：不是很强大，不能模拟通用图灵机（缺乏隐藏到隐藏的循环连接，它要求输出单元捕捉用于预测未来的关于过去的所有信息，因为输出单元明确地训练成匹配训练集的目标，它们不太能捕获关于过去输入历史的必要信息）。消除隐藏到隐藏循环的优点在于，任何基于比较时刻t的预测和时刻t的训练目标的损失函数中的所有时间步都解耦了。因此训练可以并行化，即在各个时刻t分别计算梯度。因为训练集提供输出的理想值，所以没有必要先计算前一时刻的输出。

由输出反馈到模型而产生循环连接的模型可用导师驱动过程（teacher forcing）进行训练。训练模型时，导师驱动过程不再使用最大似然准则，而在时刻t+1接收真实值$y^{(t)}$作为输入。我们可以通过检查两个时间步的序列得知这一点。条件最大似然准则是：
$$logp(y^{(1)},y^{(2)} \mid x^{(1)},x^{(2)})$$$$=logp(y^{(2)} \mid y^{(1)},x^{(1)},x^{(2)})+logp(y^{(1)} \mid x^{(1)},x^{(2)})$$在时刻t=2时，模型被训练为最大化$y^{(2)}$的条件概率。因此最大似然在训练时指定正确反馈，而不是将自己的输出反馈到模型。

使用导师驱动过程的最初动机时为了在缺乏隐藏连接的模型中避免通过时间反向传播。然而，只要隐藏单元成为较早的时间步的函数BPTT算法是必要的。因此训练某些模型时要同时使用导师驱动过程和BPTT

开环（open-loop）模式：网络输出（或者输出样本分布）反馈作为输入。
在开环模式下，完全使用导师驱动过程进行训练的缺点就会出现。这种情况下，训练期间该网络看到的输入与测试时看到的会有很大的不同。减轻此问题的一种方法是同时使用导师驱动过程和自由运行的输入进行训练，例如在展开循环的输出到输入路径上预测几个步骤的正确目标值。通过这种方式，网络可以学会考虑在训练时没有接触到的输入条件（如自由运行模式下，自身生成自身），以及将状态映射回使网络几步之后生成正确输出的状态。另一种方式是通过随意选择生成值或真实的数据值作为输入以减小训练时和测试时看到的输入之间的差别。这种方法利用了课程学习策略，逐步使用更多生成之作为输入。（？？？）
